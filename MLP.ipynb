{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE balancing technique is applied\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Importing test_train_split from sklearn library\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Input,Activation,Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "import random as rn\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "data = pd.read_csv(\"./data_syn_all_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictors and target variable from dataset\n",
    "X = data.drop('readmitted', axis=1)\n",
    "y = data['readmitted']\n",
    "oversample = SMOTE()\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               14200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 14,402\n",
      "Trainable params: 14,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_mlp = Sequential()\n",
    "model_mlp.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))\n",
    "# output layer\n",
    "model_mlp.add(Dense(num_classes, activation='sigmoid'))\n",
    "model_mlp.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model_mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3851/3851 [==============================] - 4s 1ms/step - loss: 0.0902 - accuracy: 0.5971 - val_loss: 0.1158 - val_accuracy: 0.5710\n",
      "Epoch 2/10\n",
      "3851/3851 [==============================] - 4s 1ms/step - loss: 0.0779 - accuracy: 0.5485 - val_loss: 0.1185 - val_accuracy: 0.5666\n",
      "Epoch 3/10\n",
      "3851/3851 [==============================] - 4s 1ms/step - loss: 0.0751 - accuracy: 0.5462 - val_loss: 0.1100 - val_accuracy: 0.4792\n",
      "Epoch 4/10\n",
      "3851/3851 [==============================] - 4s 1ms/step - loss: 0.0733 - accuracy: 0.5222 - val_loss: 0.1088 - val_accuracy: 0.5540\n",
      "Epoch 5/10\n",
      "3851/3851 [==============================] - 4s 1ms/step - loss: 0.0714 - accuracy: 0.5253 - val_loss: 0.1110 - val_accuracy: 0.4414\n",
      "Epoch 6/10\n",
      "3851/3851 [==============================] - 4s 1ms/step - loss: 0.0700 - accuracy: 0.5007 - val_loss: 0.1163 - val_accuracy: 0.5607\n",
      "Epoch 7/10\n",
      "3851/3851 [==============================] - 4s 1ms/step - loss: 0.0688 - accuracy: 0.5061 - val_loss: 0.1139 - val_accuracy: 0.5108\n",
      "Epoch 8/10\n",
      "3851/3851 [==============================] - 4s 1ms/step - loss: 0.0679 - accuracy: 0.4749 - val_loss: 0.1170 - val_accuracy: 0.5678\n",
      "Epoch 9/10\n",
      "3851/3851 [==============================] - 4s 1ms/step - loss: 0.0670 - accuracy: 0.4850 - val_loss: 0.1179 - val_accuracy: 0.5107\n",
      "Epoch 10/10\n",
      "3851/3851 [==============================] - 4s 1ms/step - loss: 0.0661 - accuracy: 0.4638 - val_loss: 0.1181 - val_accuracy: 0.5956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcc80f56310>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.fit(X_train, y_train, epochs=10, validation_data=(X_test,y_test), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.08999031037092209,\n",
       "  0.07740992307662964,\n",
       "  0.0748065933585167,\n",
       "  0.07242576777935028,\n",
       "  0.07091362029314041,\n",
       "  0.06953050196170807,\n",
       "  0.06850292533636093,\n",
       "  0.06751780956983566,\n",
       "  0.06665544211864471,\n",
       "  0.06576922535896301],\n",
       " 'accuracy': [0.5181400775909424,\n",
       "  0.46689337491989136,\n",
       "  0.46002694964408875,\n",
       "  0.4857882559299469,\n",
       "  0.5006736516952515,\n",
       "  0.49994319677352905,\n",
       "  0.5012661218643188,\n",
       "  0.49491915106773376,\n",
       "  0.46951496601104736,\n",
       "  0.48652684688568115],\n",
       " 'val_loss': [0.1323683261871338,\n",
       "  0.11363564431667328,\n",
       "  0.11670447885990143,\n",
       "  0.12051216512918472,\n",
       "  0.127439484000206,\n",
       "  0.10767112672328949,\n",
       "  0.11093338578939438,\n",
       "  0.11955582350492477,\n",
       "  0.1213376373052597,\n",
       "  0.1111917570233345],\n",
       " 'val_accuracy': [0.5201154351234436,\n",
       "  0.4268026649951935,\n",
       "  0.3765057325363159,\n",
       "  0.5114585757255554,\n",
       "  0.6343992352485657,\n",
       "  0.6365466713905334,\n",
       "  0.5422943830490112,\n",
       "  0.48924604058265686,\n",
       "  0.4801194369792938,\n",
       "  0.5077005624771118]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2():\n",
    "    initializer = tf.keras.initializers.he_uniform(seed=15)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=False, name='SGD')\n",
    "    model = Sequential([\n",
    "        Input(shape=(141,), name='input_layer'),\n",
    "        Dense(512, kernel_initializer=initializer, name='dense_layer1'),\n",
    "        PReLU(),\n",
    "        Dropout(rate=0.15, name='drop_out1'),\n",
    "        Dense(1, activation='sigmoid', kernel_initializer=initializer, name='output_layer'),\n",
    "        \n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer1 (Dense)         (None, 512)               72704     \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 512)               512       \n",
      "_________________________________________________________________\n",
      "drop_out1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 73,729\n",
      "Trainable params: 73,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = create_model2()\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.1213 - accuracy: 0.8464 - val_loss: 0.1168 - val_accuracy: 0.8587\n",
      "Epoch 2/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.8998 - val_loss: 0.1180 - val_accuracy: 0.8590\n",
      "Epoch 3/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0782 - accuracy: 0.9050 - val_loss: 0.1255 - val_accuracy: 0.8407\n",
      "Epoch 4/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0762 - accuracy: 0.9071 - val_loss: 0.1253 - val_accuracy: 0.8412\n",
      "Epoch 5/30\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0745 - accuracy: 0.9096 - val_loss: 0.1119 - val_accuracy: 0.8701\n",
      "Epoch 6/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0725 - accuracy: 0.9124 - val_loss: 0.1166 - val_accuracy: 0.8590\n",
      "Epoch 7/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0716 - accuracy: 0.9129 - val_loss: 0.1130 - val_accuracy: 0.8640\n",
      "Epoch 8/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0700 - accuracy: 0.9158 - val_loss: 0.1153 - val_accuracy: 0.8597\n",
      "Epoch 9/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0691 - accuracy: 0.9162 - val_loss: 0.1132 - val_accuracy: 0.8665\n",
      "Epoch 10/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0680 - accuracy: 0.9176 - val_loss: 0.1108 - val_accuracy: 0.8699\n",
      "Epoch 11/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0668 - accuracy: 0.9193 - val_loss: 0.1147 - val_accuracy: 0.8619\n",
      "Epoch 12/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9198 - val_loss: 0.1105 - val_accuracy: 0.8700\n",
      "Epoch 13/30\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.0650 - accuracy: 0.9211 - val_loss: 0.1172 - val_accuracy: 0.8569\n",
      "Epoch 14/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0641 - accuracy: 0.9223 - val_loss: 0.1186 - val_accuracy: 0.8548\n",
      "Epoch 15/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0635 - accuracy: 0.9229 - val_loss: 0.1090 - val_accuracy: 0.8736\n",
      "Epoch 16/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0626 - accuracy: 0.9244 - val_loss: 0.1183 - val_accuracy: 0.8552\n",
      "Epoch 17/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0619 - accuracy: 0.9246 - val_loss: 0.1166 - val_accuracy: 0.8578\n",
      "Epoch 18/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0613 - accuracy: 0.9255 - val_loss: 0.1118 - val_accuracy: 0.8691\n",
      "Epoch 19/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0603 - accuracy: 0.9267 - val_loss: 0.1106 - val_accuracy: 0.8718\n",
      "Epoch 20/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0597 - accuracy: 0.9271 - val_loss: 0.1107 - val_accuracy: 0.8704\n",
      "Epoch 21/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0591 - accuracy: 0.9288 - val_loss: 0.1139 - val_accuracy: 0.8647\n",
      "Epoch 22/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0585 - accuracy: 0.9291 - val_loss: 0.1101 - val_accuracy: 0.8733\n",
      "Epoch 23/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9296 - val_loss: 0.1133 - val_accuracy: 0.8676\n",
      "Epoch 24/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9304 - val_loss: 0.1175 - val_accuracy: 0.8581\n",
      "Epoch 25/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9308 - val_loss: 0.1149 - val_accuracy: 0.8634\n",
      "Epoch 26/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0562 - accuracy: 0.9318 - val_loss: 0.1204 - val_accuracy: 0.8530\n",
      "Epoch 27/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0564 - accuracy: 0.9320 - val_loss: 0.1176 - val_accuracy: 0.8584\n",
      "Epoch 28/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9322 - val_loss: 0.1181 - val_accuracy: 0.8562\n",
      "Epoch 29/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0551 - accuracy: 0.9330 - val_loss: 0.1156 - val_accuracy: 0.8649\n",
      "Epoch 30/30\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.0548 - accuracy: 0.9329 - val_loss: 0.1155 - val_accuracy: 0.8631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcc524f6970>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=30, validation_data=(X_test,y_test), batch_size=500, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset with 25 features\n",
    "# Read the dataset\n",
    "dsf = pd.read_csv(\"./data_selected30_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictors and target variable from dataset\n",
    "X = dsf.drop('readmitted', axis=1)\n",
    "y = dsf['readmitted']\n",
    "oversample = SMOTE()\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model3():\n",
    "    initializer = tf.keras.initializers.he_uniform(seed=15)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=False, name='SGD')\n",
    "    model = Sequential([\n",
    "        Input(shape=(25,), name='input_layer'),\n",
    "        Dense(512, kernel_initializer=initializer, name='dense_layer1'),\n",
    "        PReLU(),\n",
    "        Dropout(rate=0.15, name='drop_out1'),\n",
    "        Dense(1, activation='sigmoid', kernel_initializer=initializer, name='output_layer'),\n",
    "        \n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer1 (Dense)         (None, 512)               13312     \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 512)               512       \n",
      "_________________________________________________________________\n",
      "drop_out1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,337\n",
      "Trainable params: 14,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = create_model3()\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3076 - accuracy: 0.5877 - val_loss: 0.2329 - val_accuracy: 0.6232\n",
      "Epoch 2/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2297 - accuracy: 0.6317 - val_loss: 0.2166 - val_accuracy: 0.6599\n",
      "Epoch 3/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2166 - accuracy: 0.6529 - val_loss: 0.2334 - val_accuracy: 0.6131\n",
      "Epoch 4/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2111 - accuracy: 0.6650 - val_loss: 0.2264 - val_accuracy: 0.6288\n",
      "Epoch 5/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2080 - accuracy: 0.6721 - val_loss: 0.2034 - val_accuracy: 0.6888\n",
      "Epoch 6/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2046 - accuracy: 0.6807 - val_loss: 0.1869 - val_accuracy: 0.7232\n",
      "Epoch 7/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2025 - accuracy: 0.6847 - val_loss: 0.2087 - val_accuracy: 0.6719\n",
      "Epoch 8/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2000 - accuracy: 0.6904 - val_loss: 0.2410 - val_accuracy: 0.5948\n",
      "Epoch 9/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1974 - accuracy: 0.6974 - val_loss: 0.2182 - val_accuracy: 0.6467\n",
      "Epoch 10/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1948 - accuracy: 0.7029 - val_loss: 0.2204 - val_accuracy: 0.6423\n",
      "Epoch 11/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1932 - accuracy: 0.7067 - val_loss: 0.2176 - val_accuracy: 0.6492\n",
      "Epoch 12/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.7110 - val_loss: 0.2164 - val_accuracy: 0.6558\n",
      "Epoch 13/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.7131 - val_loss: 0.1937 - val_accuracy: 0.7052\n",
      "Epoch 14/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1882 - accuracy: 0.7169 - val_loss: 0.2150 - val_accuracy: 0.6576\n",
      "Epoch 15/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1863 - accuracy: 0.7200 - val_loss: 0.2257 - val_accuracy: 0.6345\n",
      "Epoch 16/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1845 - accuracy: 0.7227 - val_loss: 0.2156 - val_accuracy: 0.6572\n",
      "Epoch 17/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1836 - accuracy: 0.7258 - val_loss: 0.2127 - val_accuracy: 0.6637\n",
      "Epoch 18/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1822 - accuracy: 0.7287 - val_loss: 0.1892 - val_accuracy: 0.7137\n",
      "Epoch 19/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1810 - accuracy: 0.7302 - val_loss: 0.1932 - val_accuracy: 0.7059\n",
      "Epoch 20/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.7333 - val_loss: 0.1993 - val_accuracy: 0.6960\n",
      "Epoch 21/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1786 - accuracy: 0.7355 - val_loss: 0.1884 - val_accuracy: 0.7177\n",
      "Epoch 22/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7382 - val_loss: 0.1995 - val_accuracy: 0.6933\n",
      "Epoch 23/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7402 - val_loss: 0.1851 - val_accuracy: 0.7226\n",
      "Epoch 24/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.7417 - val_loss: 0.2105 - val_accuracy: 0.6727\n",
      "Epoch 25/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1734 - accuracy: 0.7447 - val_loss: 0.1980 - val_accuracy: 0.6959\n",
      "Epoch 26/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1723 - accuracy: 0.7467 - val_loss: 0.1970 - val_accuracy: 0.7002\n",
      "Epoch 27/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1719 - accuracy: 0.7474 - val_loss: 0.1665 - val_accuracy: 0.7635\n",
      "Epoch 28/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1694 - accuracy: 0.7519 - val_loss: 0.1978 - val_accuracy: 0.6972\n",
      "Epoch 29/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1685 - accuracy: 0.7533 - val_loss: 0.1926 - val_accuracy: 0.7094\n",
      "Epoch 30/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1673 - accuracy: 0.7556 - val_loss: 0.2116 - val_accuracy: 0.6683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcc4056ca60>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train, epochs=30, validation_data=(X_test,y_test),\n",
    "           batch_size=500, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, name='Adam')\n",
    "def create_model4():\n",
    "    initializer = tf.keras.initializers.he_uniform(seed=15)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Input(shape=(25,), name='input_layer'),\n",
    "        Dense(512, kernel_initializer=initializer, name='dense_layer1'),\n",
    "        PReLU(),\n",
    "        Dropout(rate=0.15, name='drop_out1'),\n",
    "        Dense(1, activation='sigmoid', kernel_initializer=initializer, name='output_layer'),\n",
    "        \n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer1 (Dense)         (None, 512)               13312     \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 512)               512       \n",
      "_________________________________________________________________\n",
      "drop_out1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,337\n",
      "Trainable params: 14,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = create_model4()\n",
    "model4.compile(optimizer=optimizer,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.6244 - val_loss: 0.1693 - val_accuracy: 0.7706\n",
      "Epoch 2/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2097 - accuracy: 0.6696 - val_loss: 0.1820 - val_accuracy: 0.7387\n",
      "Epoch 3/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2023 - accuracy: 0.6861 - val_loss: 0.2211 - val_accuracy: 0.6500\n",
      "Epoch 4/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1964 - accuracy: 0.6983 - val_loss: 0.2340 - val_accuracy: 0.6087\n",
      "Epoch 5/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1922 - accuracy: 0.7074 - val_loss: 0.2419 - val_accuracy: 0.5974\n",
      "Epoch 6/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1887 - accuracy: 0.7133 - val_loss: 0.2465 - val_accuracy: 0.5918\n",
      "Epoch 7/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1850 - accuracy: 0.7210 - val_loss: 0.2265 - val_accuracy: 0.6374\n",
      "Epoch 8/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1817 - accuracy: 0.7272 - val_loss: 0.1708 - val_accuracy: 0.7514\n",
      "Epoch 9/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1790 - accuracy: 0.7328 - val_loss: 0.2211 - val_accuracy: 0.6462\n",
      "Epoch 10/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1776 - accuracy: 0.7349 - val_loss: 0.2275 - val_accuracy: 0.6380\n",
      "Epoch 11/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.7399 - val_loss: 0.1711 - val_accuracy: 0.7492\n",
      "Epoch 12/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1742 - accuracy: 0.7411 - val_loss: 0.1683 - val_accuracy: 0.7559\n",
      "Epoch 13/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1728 - accuracy: 0.7435 - val_loss: 0.1693 - val_accuracy: 0.7501\n",
      "Epoch 14/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1713 - accuracy: 0.7463 - val_loss: 0.2590 - val_accuracy: 0.5766\n",
      "Epoch 15/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1706 - accuracy: 0.7481 - val_loss: 0.1566 - val_accuracy: 0.7779\n",
      "Epoch 16/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1687 - accuracy: 0.7518 - val_loss: 0.1347 - val_accuracy: 0.8206\n",
      "Epoch 17/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1681 - accuracy: 0.7526 - val_loss: 0.1505 - val_accuracy: 0.7887\n",
      "Epoch 18/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1683 - accuracy: 0.7515 - val_loss: 0.1687 - val_accuracy: 0.7543\n",
      "Epoch 19/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1651 - accuracy: 0.7571 - val_loss: 0.2366 - val_accuracy: 0.6231\n",
      "Epoch 20/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1638 - accuracy: 0.7595 - val_loss: 0.1643 - val_accuracy: 0.7632\n",
      "Epoch 21/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1641 - accuracy: 0.7600 - val_loss: 0.1662 - val_accuracy: 0.7609\n",
      "Epoch 22/30\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1635 - accuracy: 0.7605 - val_loss: 0.1849 - val_accuracy: 0.7243\n",
      "Epoch 23/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1633 - accuracy: 0.7610 - val_loss: 0.1805 - val_accuracy: 0.7295\n",
      "Epoch 24/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1599 - accuracy: 0.7673 - val_loss: 0.2055 - val_accuracy: 0.6845\n",
      "Epoch 25/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1620 - accuracy: 0.7630 - val_loss: 0.1694 - val_accuracy: 0.7501\n",
      "Epoch 26/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1592 - accuracy: 0.7689 - val_loss: 0.1662 - val_accuracy: 0.7584\n",
      "Epoch 27/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1609 - accuracy: 0.7652 - val_loss: 0.1735 - val_accuracy: 0.7483\n",
      "Epoch 28/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1613 - accuracy: 0.7652 - val_loss: 0.1983 - val_accuracy: 0.6986\n",
      "Epoch 29/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1603 - accuracy: 0.7663 - val_loss: 0.1968 - val_accuracy: 0.7009\n",
      "Epoch 30/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.7688 - val_loss: 0.1801 - val_accuracy: 0.7369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcc91c12160>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train, y_train, epochs=30, validation_data=(X_test,y_test),\n",
    "           batch_size=500, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, name='Adam')\n",
    "def create_model5():\n",
    "    initializer = tf.keras.initializers.he_uniform(seed=15)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Input(shape=(25,), name='input_layer'),\n",
    "        Dense(512, kernel_initializer=initializer, name='dense_layer1'),\n",
    "        PReLU(),\n",
    "        Dropout(rate=0.15, name='drop_out1'),\n",
    "        Dense(1, activation='sigmoid', kernel_initializer=initializer, name='output_layer'),\n",
    "        \n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer1 (Dense)         (None, 512)               13312     \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 512)               512       \n",
      "_________________________________________________________________\n",
      "drop_out1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,337\n",
      "Trainable params: 14,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = create_model5()\n",
    "model5.compile(optimizer=optimizer,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3133 - accuracy: 0.5859 - val_loss: 0.2074 - val_accuracy: 0.6783\n",
      "Epoch 2/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2310 - accuracy: 0.6308 - val_loss: 0.2473 - val_accuracy: 0.5772\n",
      "Epoch 3/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2167 - accuracy: 0.6516 - val_loss: 0.1971 - val_accuracy: 0.7109\n",
      "Epoch 4/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2121 - accuracy: 0.6630 - val_loss: 0.2054 - val_accuracy: 0.6800\n",
      "Epoch 5/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2083 - accuracy: 0.6714 - val_loss: 0.2012 - val_accuracy: 0.6942\n",
      "Epoch 6/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2051 - accuracy: 0.6792 - val_loss: 0.1951 - val_accuracy: 0.7065\n",
      "Epoch 7/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2029 - accuracy: 0.6858 - val_loss: 0.2124 - val_accuracy: 0.6634\n",
      "Epoch 8/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1999 - accuracy: 0.6912 - val_loss: 0.1961 - val_accuracy: 0.7027\n",
      "Epoch 9/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1979 - accuracy: 0.6955 - val_loss: 0.2080 - val_accuracy: 0.6721\n",
      "Epoch 10/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1962 - accuracy: 0.7003 - val_loss: 0.2335 - val_accuracy: 0.6158\n",
      "Epoch 11/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1937 - accuracy: 0.7062 - val_loss: 0.2146 - val_accuracy: 0.6585\n",
      "Epoch 12/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1916 - accuracy: 0.7094 - val_loss: 0.1895 - val_accuracy: 0.7147\n",
      "Epoch 13/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1903 - accuracy: 0.7118 - val_loss: 0.2034 - val_accuracy: 0.6854\n",
      "Epoch 14/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1881 - accuracy: 0.7157 - val_loss: 0.1741 - val_accuracy: 0.7475\n",
      "Epoch 15/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1870 - accuracy: 0.7199 - val_loss: 0.2094 - val_accuracy: 0.6722\n",
      "Epoch 16/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1855 - accuracy: 0.7213 - val_loss: 0.1957 - val_accuracy: 0.6995\n",
      "Epoch 17/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1838 - accuracy: 0.7252 - val_loss: 0.1830 - val_accuracy: 0.7275\n",
      "Epoch 18/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1829 - accuracy: 0.7265 - val_loss: 0.1949 - val_accuracy: 0.7043\n",
      "Epoch 19/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1811 - accuracy: 0.7303 - val_loss: 0.2086 - val_accuracy: 0.6728\n",
      "Epoch 20/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1804 - accuracy: 0.7322 - val_loss: 0.2084 - val_accuracy: 0.6759\n",
      "Epoch 21/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1785 - accuracy: 0.7357 - val_loss: 0.1868 - val_accuracy: 0.7205\n",
      "Epoch 22/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1780 - accuracy: 0.7367 - val_loss: 0.2179 - val_accuracy: 0.6577\n",
      "Epoch 23/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1757 - accuracy: 0.7410 - val_loss: 0.2229 - val_accuracy: 0.6430\n",
      "Epoch 24/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1749 - accuracy: 0.7424 - val_loss: 0.2023 - val_accuracy: 0.6913\n",
      "Epoch 25/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1737 - accuracy: 0.7448 - val_loss: 0.2369 - val_accuracy: 0.6222\n",
      "Epoch 26/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1727 - accuracy: 0.7470 - val_loss: 0.1973 - val_accuracy: 0.7009\n",
      "Epoch 27/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1715 - accuracy: 0.7481 - val_loss: 0.1921 - val_accuracy: 0.7104\n",
      "Epoch 28/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1708 - accuracy: 0.7499 - val_loss: 0.1979 - val_accuracy: 0.6984\n",
      "Epoch 29/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1694 - accuracy: 0.7526 - val_loss: 0.1768 - val_accuracy: 0.7414\n",
      "Epoch 30/30\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1686 - accuracy: 0.7528 - val_loss: 0.2061 - val_accuracy: 0.6809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcc70c9d490>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(X_train, y_train, epochs=30, validation_data=(X_test,y_test),\n",
    "           batch_size=500, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "data = pd.read_csv(\"./data_top25_dfeatures.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    88026\n",
       "1    11314\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['readmitted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictors and target variable from dataset\n",
    "X = data.drop('readmitted', axis=1)\n",
    "y = data['readmitted']\n",
    "oversample = SMOTE(sampling_strategy=0.8)\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79472, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    70421\n",
       "1     9051\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126757, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    70421\n",
       "1    56336\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, name='Adam')\n",
    "def create_model6():\n",
    "    initializer = tf.keras.initializers.he_uniform(seed=15)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Input(shape=(25,), name='input_layer'),\n",
    "        Dense(64, kernel_initializer=initializer, name='dense_layer1'),\n",
    "        PReLU(),\n",
    "        Dropout(rate=0.15, name='drop_out1'),\n",
    "        Dense(1, activation='sigmoid', kernel_initializer=initializer, name='output_layer'),\n",
    "        \n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer1 (Dense)         (None, 64)                1664      \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 64)                64        \n",
      "_________________________________________________________________\n",
      "drop_out1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,793\n",
      "Trainable params: 1,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = create_model6()\n",
    "model6.compile(optimizer=optimizer,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2536/2536 [==============================] - 2s 828us/step - loss: 0.2699 - accuracy: 0.6646 - val_loss: 0.1780 - val_accuracy: 0.7447\n",
      "Epoch 2/25\n",
      "2536/2536 [==============================] - 2s 789us/step - loss: 0.1969 - accuracy: 0.6995 - val_loss: 0.1968 - val_accuracy: 0.7253\n",
      "Epoch 3/25\n",
      "2536/2536 [==============================] - 2s 785us/step - loss: 0.1958 - accuracy: 0.7017 - val_loss: 0.1969 - val_accuracy: 0.6960\n",
      "Epoch 4/25\n",
      "2536/2536 [==============================] - 2s 784us/step - loss: 0.1950 - accuracy: 0.7046 - val_loss: 0.1945 - val_accuracy: 0.7072\n",
      "Epoch 5/25\n",
      "2536/2536 [==============================] - 2s 792us/step - loss: 0.1945 - accuracy: 0.7059 - val_loss: 0.2407 - val_accuracy: 0.5770\n",
      "Epoch 6/25\n",
      "2536/2536 [==============================] - 2s 791us/step - loss: 0.1952 - accuracy: 0.7049 - val_loss: 0.1967 - val_accuracy: 0.7037\n",
      "Epoch 7/25\n",
      "2536/2536 [==============================] - 2s 795us/step - loss: 0.1945 - accuracy: 0.7050 - val_loss: 0.2006 - val_accuracy: 0.6901\n",
      "Epoch 8/25\n",
      "2536/2536 [==============================] - 2s 785us/step - loss: 0.1934 - accuracy: 0.7067 - val_loss: 0.2109 - val_accuracy: 0.6676\n",
      "Epoch 9/25\n",
      "2536/2536 [==============================] - 2s 792us/step - loss: 0.1935 - accuracy: 0.7084 - val_loss: 0.2100 - val_accuracy: 0.6778\n",
      "Epoch 10/25\n",
      "2536/2536 [==============================] - 2s 785us/step - loss: 0.1931 - accuracy: 0.7091 - val_loss: 0.1781 - val_accuracy: 0.7455\n",
      "Epoch 11/25\n",
      "2536/2536 [==============================] - 2s 793us/step - loss: 0.1929 - accuracy: 0.7093 - val_loss: 0.1925 - val_accuracy: 0.7048\n",
      "Epoch 12/25\n",
      "2536/2536 [==============================] - 2s 798us/step - loss: 0.1926 - accuracy: 0.7096 - val_loss: 0.2044 - val_accuracy: 0.6824\n",
      "Epoch 13/25\n",
      "2536/2536 [==============================] - 2s 803us/step - loss: 0.1924 - accuracy: 0.7117 - val_loss: 0.1642 - val_accuracy: 0.7695\n",
      "Epoch 14/25\n",
      "2536/2536 [==============================] - 2s 793us/step - loss: 0.1921 - accuracy: 0.7109 - val_loss: 0.1705 - val_accuracy: 0.7640\n",
      "Epoch 15/25\n",
      "2536/2536 [==============================] - 2s 791us/step - loss: 0.1916 - accuracy: 0.7116 - val_loss: 0.1483 - val_accuracy: 0.8024\n",
      "Epoch 16/25\n",
      "2536/2536 [==============================] - 2s 782us/step - loss: 0.1920 - accuracy: 0.7105 - val_loss: 0.2090 - val_accuracy: 0.6727\n",
      "Epoch 17/25\n",
      "2536/2536 [==============================] - 2s 785us/step - loss: 0.1913 - accuracy: 0.7118 - val_loss: 0.1945 - val_accuracy: 0.7191\n",
      "Epoch 18/25\n",
      "2536/2536 [==============================] - 2s 781us/step - loss: 0.1915 - accuracy: 0.7132 - val_loss: 0.1739 - val_accuracy: 0.7494\n",
      "Epoch 19/25\n",
      "2536/2536 [==============================] - 2s 784us/step - loss: 0.1910 - accuracy: 0.7124 - val_loss: 0.1527 - val_accuracy: 0.7960\n",
      "Epoch 20/25\n",
      "2536/2536 [==============================] - 2s 788us/step - loss: 0.1908 - accuracy: 0.7132 - val_loss: 0.1674 - val_accuracy: 0.7652\n",
      "Epoch 21/25\n",
      "2536/2536 [==============================] - 2s 796us/step - loss: 0.1908 - accuracy: 0.7126 - val_loss: 0.1765 - val_accuracy: 0.7546\n",
      "Epoch 22/25\n",
      "2536/2536 [==============================] - 2s 792us/step - loss: 0.1908 - accuracy: 0.7129 - val_loss: 0.1837 - val_accuracy: 0.7375\n",
      "Epoch 23/25\n",
      "2536/2536 [==============================] - 2s 802us/step - loss: 0.1904 - accuracy: 0.7137 - val_loss: 0.2011 - val_accuracy: 0.6856\n",
      "Epoch 24/25\n",
      "2536/2536 [==============================] - 2s 788us/step - loss: 0.1907 - accuracy: 0.7143 - val_loss: 0.1459 - val_accuracy: 0.8072\n",
      "Epoch 25/25\n",
      "2536/2536 [==============================] - 2s 791us/step - loss: 0.1903 - accuracy: 0.7149 - val_loss: 0.2043 - val_accuracy: 0.6753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc60999af10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(X_train, y_train, epochs=25, validation_data=(X_test,y_test),\n",
    "           batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-2ccbe829e608>:4: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Accuracy: 0.675257\n",
      "Precision: 0.148279\n",
      "Recall: 0.390190\n",
      "F1 score: 0.214894\n",
      "ROC AUC: 0.580157\n",
      "[[12533  5072]\n",
      " [ 1380   883]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predict probabilities for test set\n",
    "yhat_probs = model6.predict(X_test, verbose=0)\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = model6.predict_classes(X_test, verbose=0)\n",
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, yhat_classes)\n",
    "print('F1 score: %f' % f1)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, yhat_probs)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, yhat_classes)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc609c08070>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.723, Test: 0.675\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-527702f9a904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m211\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model6.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = model6.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss during training\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(model6.history.history['loss'], label='train')\n",
    "pyplot.plot(model6.history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "# plot accuracy during training\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.plot(model6.history.history['accuracy'], label='train')\n",
    "pyplot.plot(model6.history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
